\documentclass[10pt, ngerman]{beamer}

\usetheme{Madrid} 

% ----------------------
% Pakete
% ----------------------
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[ngerman]{babel}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{geometry}
\usepackage{listings}
\usepackage{float}
\usepackage{mathtools} 
\usepackage{tikz}
\usepackage{pgfplots}
\usetikzlibrary{positioning, arrows.meta}
\pgfplotsset{compat=1.18}

\hypersetup{
    pdfborder={0 0 0},    % Entfernt alle Rahmen um Links
}

% ----------------------
% C++ Code Settings
% ----------------------
\lstset{
    language=C++,
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue},
    commentstyle=\color{gray},
    stringstyle=\color{red},
    numbers=left,
    numberstyle=\tiny,
    stepnumber=1,
    numbersep=5pt,
    frame=single,
    breaklines=true,
    showstringspaces=false
}

\title[Skalierbarkeit paralleles Sortieren]{Untersuchung der Skalierbarkeit von parallelem Sortieren auf einem Multicore-Prozessor}
\subtitle{Verteidigung der Bachelorarbeit}
\author{Leon Zoerner}
\institute{Informatik}
\date{\today}

\include{Kapitel/Kapitel}

\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}{Agenda}
    \tableofcontents
\end{frame}

\section{Einleitung}
\begin{frame}{Einleitung: Motivation}
    \textbf{Motivation:}
    \Motivation
\end{frame}

\begin{frame}{Einleitung: Zielsetzung und Forschungsfrage}
    \textbf{Zielsetzung und Forschungsfrage:}
    \ZielsetzungUndForschungsfrage
\end{frame}

\section{Theoretische Grundlagen}
\begin{frame}{Theoretische Grundlagen}
    \textbf{Hinweis zur mathematischen Darstellung}
    Die in dieser Arbeit genutzten mathematischen Beschreibungen und Formeln beziehen sich durchgehend auf die konkret implementierten Programmstrukturen und können daher von allgemeinen Standardformeln abweichen.
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort und Mergesort}
    Sowohl \textbf{Quicksort} als auch \textbf{Mergesort} basieren auf dem \emph{Teile-und-Herrsche}-Prinzip und sind rekursive Sortieralgorithmen. Dabei wird das zu sortierende Array wiederholt in kleinere Teilprobleme zerlegt, die unabhängig voneinander verarbeitet werden.
\end{frame}

\begin{frame}{Sortieralgorithmen: Mergesort}
    Das Grundprinzip von \textbf{Mergesort} besteht darin, zwei bereits sortierte Teilarrays zu einem sortierten Array zusammenzuführen. In dieser Arbeit wird das unsortierte Eingabearray rekursiv in zwei möglichst gleich große Hälften geteilt, bis jedes Teilarray nur noch aus einem einzelnen Element besteht. Da ein Array mit einem Element per Definition sortiert ist, beginnt anschließend der sogenannte \emph{Merge-Schritt (Mischen)}. In diesem Schritt werden jeweils zwei sortierte Teilarrays zu einem sortierten Gesamtergebnis zusammengeführt.
    \newline
    Hierfür werden beide Teilarrays mit einer Gesamtlänge von \(n\) Elementen sequenziell durchlaufen und die Elemente verglichen.
    Der Aufwand pro Merge-Schritt entspricht dabei \(n\) Vergleichen, da jedes Element genau einmal betrachtet wird, sowie \(2n\) Lese- und Schreibzugriffen, da die Elemente temporär in ein neues Array der Größe \(n\) geschrieben und von dort wieder gelesen werden müssen.
\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Mergesort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
    void Mergesort::mergesort(int *liste, const int links, const int rechts) {
        int laenge = rechts - links + 1;
        if (laenge > 1) {
            int mitte = links + ((rechts - links) / 2);
            mergesort(liste, links, mitte);      // A
            mergesort(liste, mitte + 1, rechts); // B
            mischen(liste, links, mitte, rechts, laenge);
        }
    }
    \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Mergesort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
    void Mergesort::mischen(int *liste, int links, const int mitte, const int rechts, const int lange) {
        int *listeB = new int[lange];
    
        // Kopiere nach listeB
        for (int i = links; i < mitte + 1; i++) {
            listeB[i - links] = liste[i];
        }
        for (int i = mitte + 1; i < rechts + 1; i++) {
            listeB[lange - 1 + mitte + 1 - i] = liste[i];
        }
    
        // Sortiere liste
        int i = 0;         // links
        int j = lange - 1; // rechts
        int k = links;     // links
        while (i < j) {
            if (listeB[i] < listeB[j]) {
                liste[k] = listeB[i];
                i++;
            } else {
                liste[k] = listeB[j];
                j--;
            }
            k++;
        }
        liste[rechts] = listeB[i];
    
        delete[] listeB;
    };    
    \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Mergesort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
        ...
        // Sortiere liste
        int i = 0;         // links
        int j = lange - 1; // rechts
        int k = links;     // links
        while (i < j) {
            if (listeB[i] < listeB[j]) {
                liste[k] = listeB[i];
                i++;
            } else {
                liste[k] = listeB[j];
                j--;
            }
            k++;
        }
        liste[rechts] = listeB[i];
        delete[] listeB;
    };    
    \end{lstlisting}

\end{frame}

\begin{frame}{Sortieralgorithmen: Mergesort}
    \begin{flalign*}
        T(n)    & = m_1 + m_2 + n                                                                                                             & \\
        T(n)    & = T \left ( \left \lfloor \frac{n}{2} \right \rfloor \right) + T \left ( \left \lceil \frac{n}{2} \right \rceil \right) + n & \\
        T(n)    & = 2 \cdot T \left( \frac{n}{2} \right) + n,                                                                                 & \\
        T(n)    & = n \cdot \log_2(n) + n,                                                                                                    & \\
        O(T(n)) & = O(n \log n).                                                                                                              &
    \end{flalign*}
\end{frame}


\begin{frame}{Sortieralgorithmen: Mergesort}
    Balancierter Binärbaum für $n = 16$
    \newline
    \newline
    \BalancierterBinaerbaumNSechzehn
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort}
    \textbf{Quicksort} ist im Grundaufbau ähnlich strukturiert, unterscheidet sich jedoch wesentlich im Ablauf. Die Liste wird nicht zwingend in zwei gleich große Hälften geteilt. Stattdessen wird zunächst ein sogenanntes \emph{Pivot-Element} gewählt, anhand dessen die Liste in einen kleineren und einen größeren Teil partitioniert wird. Dieser Partitionierungsschritt erfolgt vor den rekursiven Selbstaufrufen.
    Beim Partitionieren wird die Liste so umsortiert, dass alle Elemente, die kleiner als das Pivotelement sind, links davon stehen und alle Elemente, die größer sind, rechts davon stehen. Dabei werden die Elemente auf beiden Seiten entsprechend getauscht.
\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Quicksort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
    void Quicksort::quicksort(int *liste, const int links, const int rechts) {
        if (links < rechts) {
            int ml, mr;
            partitioniere(liste, links, rechts, ml, mr);
            quicksort(liste, links, ml);
            quicksort(liste, mr, rechts);
        }
    };
    \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Quicksort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
    void Quicksort::partitioniere(int *liste, const int links, const int rechts, int &ml, int &mr) {
        int i = links;
        int j = rechts;
        int mitte = links + ((rechts - links) / 2);
        int p = liste[mitte];
        while (i <= j) {
            while (liste[i] < p) {
                i++;
            }
            while (liste[j] > p) {
                j--;
            }
            if (i <= j) {
                vertausche(liste, i, j);
                i++;
                j--;
            }
        };
        ml = j; mr = i;
    };
    \end{lstlisting}

\end{frame}

\begin{frame}[fragile]{Sortieralgorithmen: Quicksort}

    \begin{lstlisting}[language=C++, basicstyle=\ttfamily\small]
    void Quicksort::vertausche(int *liste, const int a, const int b) {
        int temp = liste[a];
        liste[a] = liste[b];
        liste[b] = temp;
    };
    \end{lstlisting}

\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort Best-Case}
    \textbf{Best-Case} von Quicksort:
    \begin{flalign*}
        T(n)    & = q_1 + q_2 + n                                                                                                             & \\
        T(n)    & = T \left ( \left \lfloor \frac{n}{2} \right \rfloor \right) + T \left ( \left \lceil \frac{n}{2} \right \rceil \right) + n & \\
        T(n)    & = 2 \cdot T \left( \frac{n}{2} \right) + n,                                                                                 & \\
        T(n)    & = n \cdot \log_2(n) + n,                                                                                                    & \\
        O(T(n)) & = O(n \log n).                                                                                                              &
    \end{flalign*}
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort Best-Case}
    Balancierter Binärbaum für $n = 16$
    \newline
    \newline
    \BalancierterBinaerbaumNSechzehn
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort}
    Der \textbf{Worst-Case} von Quicksort ist:
    \begin{flalign*}
        T(n)    & = q_1 + q_2 + n                      & \\
        T(n)    & = T(n-1) + 1 + n,                    & \\
        T(n)    & = \frac{1}{2} \cdot ( n^2 + n ) + n, & \\
        O(T(n)) & = O(n^2).                            &
    \end{flalign*}
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort}
    Maximal unbalancierter Binärbaum für $n = 4$ \textbf{Worst-Case}:
    \newline
    \newline
    \QuicksortWorstCaseBaum
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort Average-Case}
    \begin{itemize}
        \item Nicht zielführend, da eine einzige Laufzeit nie die Laufzeit des echten Zufalls abbilden kann.
        \item Die echte Laufzeit wird fast nie Durchschnitt oder Median sein.
        \item Man sollte generell eher vom gesamten Bereich, der vom Best-Case bis hin zum Worst-Case reicht, ausgehen.
        \item Aus Sicht des Programmablaufs (unbalancierte Baumstruktur) liegt man im Zufall eher am Best Case als am Worst Case.
    \end{itemize}
\end{frame}


\begin{frame}{Sortieralgorithmen: Quicksort Average-Case}
    Der \textbf{heuristisch betrachtete Average-Case} von Quicksort ist:
    \\[-0.8cm]
    \begin{flalign*}
        T(n)    & = q_1 + q_2 + n                                                                                                                                 & \\
        q_1     & = T\left( \frac{1 + \dots + (n-1)}{n-1} \right) = T\left( n \cdot \frac{n-1}{2} \cdot \frac{1}{n-1} \right) = T\left( \frac{n}{2} \right) = q_2 & \\
        T(n)    & = 2 \cdot T\left( \frac{n}{2} \right) + n                                                                                                       & \\
        T(n)    & = n \cdot \log_2(n) + n                                                                                                                         & \\
        O(T(n)) & = O(n \log n).                                                                                                                                  &
    \end{flalign*}
    \\[-0.4cm]
    \begin{itemize}
        \item Mathematisch falsche Herangehensweise. Dadurch wird selbst der Worst-Case zu $T(n/2)$.
        \item Soll mathematisch nur zeigen, dass man eher am Best-Case als am Worst-Case liegt.
        \item Jedem sollte klar sein, dass man nur im Best-Case auch die Laufzeit des Best-Case erreichen kann und somit der echte Average-Case nie die Laufzeit des Best-Case haben kann.
        \item Der echte Average Case wird über den Durchschnitt von $T(*)$ berechnet und nicht über die möglichen Werte von $n$, die $T(*)$ annehmen kann.
    \end{itemize}
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort Average-Case}
    \includegraphics[width=0.9\textwidth]{Abbildungen/Ernst2023S611.jpg}
    \newline
    \footnotesize
    Quelle: Datenstrukturen, B{\"a}ume und Graphen \cite[S.~611]{Ernst2023}
\end{frame}

\begin{frame}{Sortieralgorithmen: Quicksort Average-Case}
    Der echte \textbf{Average-Case} ist:
    \begin{flalign*}
        T_{\text{avg}}(n) & \approx 1.39 \cdot T_{\text{best}}(n)     & \\
        T_{\text{avg}}(n) & \approx 1.39 \cdot (n \cdot log_2(n) + n) & \\
    \end{flalign*}
    \footnotesize
    Quelle: 4. Auflage, \textit{Algorithmen}, Sedgewick \cite{Sedgewick2014DE}
\end{frame}

\begin{frame}{Grundlagen der Parallelisierung}
    \begin{itemize}
        \item \textbf{Amdahlsches Gesetz}, Speedup $1/p$
        \item theoretischer Speedup aufgrund von Overheads nie erreichbar
    \end{itemize}
    \begin{flalign*}
        p       & = \text{Thread-Anzahl} ,                                                                                                   & \\
        f       & = \text{serieller Code, wobei } 0 < f \le 1 ,                                                                              & \\
        t ( p ) & = \underbrace{f \cdot t(1)}_{\text{serielle Arbeit}} + \underbrace{(1-f) \cdot \frac{t(1)}{p}}_{\text{parallele Arbeit}} . &
    \end{flalign*}
    $f$ nahe 0 bedeutet,
    dass der Code fast die ganze Zeit alle Recheneinheiten beschäftigt hält.
    Dies impliziert, dass sein Nebenläufigkeitsgrad immer gleich oder höher als die Anzahl der parallelen
    Rechenknoten ist.
    $f$ nahe 1 bedeutet, dass der Großteil unseres Codes nicht parallel läuft.
    \cite{Weinzierl2024}
    \begin{itemize}
        \item Es ist kein linearer Speedup ($1/p$), daher nur eine eigene $T(n,p)$-Formel statt des exakten Amdahlschen Gesetzes.
    \end{itemize}
\end{frame}

\begin{frame}{Thread-Modelle, Overheads und Skalierungsgrenzen}
    \begin{itemize}
        \item Overheads
        \item Skalierungsgrenzen
        \item Thread-Modelle, Implementierungsstrategien
    \end{itemize}
\end{frame}

\begin{frame}{Overheads}
    \begin{itemize}
        \item Betrachten \textbf{Overheads} aus siecht eines Softwarearchitekten, für den die gesamte Hardware eine Blackbox ist.
        \item \textbf{Overheads} (Zusatzlaufzeiten) verhindern theoretisch ideale Zeitersparnis.
        \item \textbf{Overheads}:
              \begin{itemize}
                  \item Initialisierungs- und Join-Zeiten
                  \item Destruktoren
                  \item Synchronisation
                  \item Swapping (Kontextwechsel)
                  \item Speicherlatenzen (begrenzte Speichergröße, Cache-Misses, Datenübertragungsgeschwindigkeit (Latenzen), Datenübertragungsrate)
                  \item ...
              \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Overheads (Text)}
    In der Praxis verursachen Threads verschiedene \textbf{Overheads} (Zusatzlaufzeiten), die verhindern, dass eine theoretisch ideale Zeitersparnis erreicht wird. Zu diesen Overheads zählen primär die Initialisierungs- und Join-Zeiten, die Laufzeiten von Destruktoren sowie die notwendige Synchronisation bei Abhängigkeiten zwischen Threads. Um die Datenkonsistenz zu gewährleisten, müssen Mechanismen wie Sperren (Mutexe) oder Barrieren (Synchronisationspunkte) eingesetzt werden, welche zusätzliche Wartezeiten und Verwaltungsoverheads verursachen. Parallel dazu setzen Hardware-Limitierungen der Skalierung Grenzen. Hierbei beeinflussen Context-Switching-Zeiten bei Überbelegung der Kerne (Oversubscription), die begrenzte Anzahl physischer Kerne (im Testsystem 8 physische bzw. 16 logische Prozessoren) sowie eine erhöhte Rate an Cache-Misses bei steigender Thread-Anzahl die Performance negativ. Letzteres führt dazu, dass vermehrt Daten aus dem RAM geladen werden müssen, wodurch das System je nach Anwendungsfall eher durch die Bandbreite und Speicherlatenz des Speichercontrollers (Memory Bound) als durch die Rechenleistung der CPU-Kerne begrenzt wird. Zudem ist zwischen physischen und logischen Prozessoren zu unterscheiden, da letztere aufgrund geteilter Hardware-Ressourcen weniger effizient skalieren.
\end{frame}

\begin{frame}{Skalierungsgrenzen: Hardware-Grenze CPU}
    \begin{itemize}
        \item Begrenzte Anzahl physischer Kerne (im Testsystem 8 physische bzw. 16 logische Prozessoren).
        \item Je größer die Leistungsaufnahme der CPU ist, desto ineffizienter arbeitet sie.
        \item Begrenzte maximale Leistungsaufnahme (Thermal Design Power, TDP), welche dafür sorgt, dass mehr Threads nicht unbedingt mehr Leistung bedeuten.
        \item Leistungsaufnahme wird größtenteils zu Abwärme, die im schlimmsten Fall zur Runtertaktung (Thermal Throttling) einzelner CPU-Kerne führt.
        \item Der wenige Rest der Leistungsaufnahme baut ein sich ständig wechselndes Magnetfeld auf, welches dabei Störströme (Kreisströme) induziert.
    \end{itemize}
\end{frame}

\begin{frame}{Overheads: Hardware-Grenze CPU (Text)}
    Eine weitere wesentliche Hardware-Grenze stellt die CPU dar. Moderne CPUs sind durch eine maximale Leistungsaufnahme (Thermal Design Power, TDP) begrenzt. Eine höhere Auslastung aller Kerne führt daher nicht zwangsläufig zu proportional höherer Leistung. Beispielsweise weist die genutzte CPU einen Single-Core-Boost-Takt von 4,75 GHz auf, jedoch nur einen All-Core-Takt von 4,6 GHz, wodurch einzelne Threads bei geringer Auslastung performanter laufen. Zudem wird ein Großteil der TDP als Abwärme freigegeben, die effizient abgeführt werden muss. Bei unzureichender Kühlung oder Überschreitung thermischer Grenzen kommt es zur automatischen thermischen Drosselung (Thermal Throttling) der CPU, wodurch der Takt des jeweiligen Kerns temporär reduziert wird.
    Der wenige Rest der TDP wird in elektromagnetische Felder umgewandelt, welche dann für Störströme (Kreisströme) sorgen.
    Diese Faktoren beeinflussen die Performance ebenfalls negativ.
\end{frame}

\begin{frame}{Thread-Modelle, Implementierungsstrategien}
    \begin{itemize}
        \item Jeden Codeabschnitt ohne sequentielle Abhängigkeiten in einen neuen Thread auslagern
        \item Thread-Anzahl begrenzen, da sonst oft Overheads dominieren.
        \item Nutzen von Worker-Threads (Threadpool)
        \item Work-Stealing-Ansatz
        \item Nur neue Aufgaben auf Aufgabenliste legen, wenn freie Worker-Threads vorhanden sind.
    \end{itemize}
\end{frame}

\begin{frame}{Thread-Modelle, Implementierungsstrategien (Text)}
    Hinsichtlich der Implementierung existieren verschiedene Ansätze. Die simpelste Methode besteht darin, jeden Codeabschnitt ohne sequentielle Abhängigkeiten in einen neuen Thread auszulagern. Dies ist jedoch oft kontraproduktiv, da ein Übermaß an Threads zu Performance-Verlusten durch Context Switching und hohen Speicherverbrauch führt. In der Praxis wird die Thread-Anzahl daher meist limitiert.
    \newline
    Eine Optimierung stellt die Nutzung von \textbf{Worker-Threads} dar. Hierbei werden Threads einmalig initialisiert und verbleiben über die gesamte Laufzeit aktiv, um kontinuierlich neue Aufgaben abzuarbeiten, anstatt nach jeder Aufgabe zerstört zu werden. Eine weiterführende Strategie ist das Dynamic Scheduling (oder Work-Stealing-Ansätze), bei dem Aufgaben nur dann zugewiesen werden, wenn Ressourcen frei sind. Sind alle Worker-Threads belegt, kann der aufrufende Thread die Aufgabe selbst bearbeiten, um Wartezeiten zu minimieren. Die Vor- und Nachteile dieser Strategien werden im Abschnitt der Implementierungsvarianten und der Messungen detailliert analysiert.
\end{frame}

\begin{frame}{Begriffserklärung: Worker-Thread und Work-Stealing}
    \WorkerThreadErklaerung
    \\[1cm]
    \WorkStealingErklaerung
\end{frame}

\begin{frame}{Begriffserklärung Work-Stealing-ähnliche Ansatz}
    \begin{figure}[h]
        \centering
        \scalebox{0.9}{
            \WorkerthreadsAbildung
        }
        \caption[Work-Stealing-ähnlicher Ansatz mit gemeinsamer Aufgaben-Queue]{Work-Stealing-ähnlicher Ansatz mit gemeinsamer Aufgaben-Queue: Threads entnehmen Aufgaben aus der Queue und können neue Aufgaben auf diese legen.}
        \label{fig:workstealing_dynamisch}
    \end{figure}
\end{frame}

\begin{frame}{Begriffserklärung Work-Stealing-ähnliche Ansatz}
    \WorkStealingAehnlichErklaerung
\end{frame}

\section{Methodik und Versuchsaufbau}
\begin{frame}{Methodik und Versuchsaufbau}
    \begin{itemize}
        \item Messumgebung und Hardware
        \item Implementierungsvarianten
        \item Programmablauf als Baumstruktur
        \item Parallele Implementierungsvarianten Code
        \item Optimierung
        \item Messmethodik
    \end{itemize}
\end{frame}

\begin{frame}{Messumgebung und Hardware}
    \begin{itemize}
        \item CPU: AMD Ryzen 7 5800x, 8-Kern-CPU (8 physische Kerne, 16 logische Prozessoren)
        \item 32\,GB Ram: DDR4-3200, CL16-18-18-38 (2 Kits, insgesamt 4×8\,GB)
        \item Betriebssystem: Windows~10 Version~22H2
        \item Der Code wurde in \textbf{C++20} implementiert und mittels \textbf{CMake} (Version 3.26.4) sowie dem \textbf{MSVC-Compiler} (Version 14.44.35207) unter Verwendung des \textbf{MultiThreaded}-Flags kompiliert.
        \item Im integrierten Terminal von Visual Studio Code.
        \item In einer Release-Konfiguration (also mit Compiler-Optimierungen).
    \end{itemize}
\end{frame}

\begin{frame}{Messumgebung und Hardware}
    \MessumgebungUndHardware
\end{frame}

\begin{frame}{Implementierungsvarianten}
    Im Rahmen dieser Arbeit wurden folgende Implementierungsvarianten für Mergesort und Quicksort umgesetzt:
    \begin{itemize}
        \item eine rekursiv sequenzielle Variante,
        \item eine rekursive Variante mit Thread-Erzeugung bis zu einer Tiefe $e$, welche eine Thread-Anzahl von $2^e$ unterstützt (tiefenbasierte Thread-Erzeugung),
        \item eine Worker-Thread-Variante basierend auf einem Work-Stealing-ähnlichen Ansatz mit $N$ Threads, umgesetzt als aufgabenbasierte Rekursionsverwaltung (Work-Stealing-Variante).
    \end{itemize}
\end{frame}

\begin{frame}{Implementierungsvarianten: Formeln: parallel Mergesort}
    \begin{flalign*}
        p         & = \text{Thread-Anzahl}                                                                               &  & \\
        e         & = \log_2(p)                                                                                          &  & \\
        T(n,e)    & = \begin{cases}
                          2 \cdot T\left(\frac{n}{2}, 0\right) + n   & \text{, wenn } e = 0 \\
                          1 \cdot T\left(\frac{n}{2}, e-1\right) + n & \text{, wenn } e > 0
                      \end{cases}                                 &  &                                       \\
        T(n,p)    & = 2n \left( 1 - \frac{1}{p} \right) + \frac{n}{p} \cdot \log_2\left(\frac{n}{p}\right) + \frac{n}{p} &  & \\
        O(T(n,p)) & = O\left( \frac{n}{p} \cdot \log_2(n) + n \right)                                                    &  & \\
        e_{\max}  & = \log_2(n)                                                                                          &  & \\
        p_{\max}  & = n
    \end{flalign*}
\end{frame}

\begin{frame}{Implementierungsvarianten: Formeln: parallel Quicksort}
    Der \textbf{Best-Case} von Quicksort ist:
    \begin{flalign*}
        p         & = \text{Thread-Anzahl}                                                                               &  & \\
        e         & = \log_2(p)                                                                                          &  & \\
        T(n,e)    & = \begin{cases}
                          2 \cdot T\left(\frac{n}{2}, 0\right) + n   & \text{, wenn } e = 0 \\
                          1 \cdot T\left(\frac{n}{2}, e-1\right) + n & \text{, wenn } e > 0
                      \end{cases}                                 &  &                                       \\
        T(n,p)    & = 2n \left( 1 - \frac{1}{p} \right) + \frac{n}{p} \cdot \log_2\left(\frac{n}{p}\right) + \frac{n}{p} &  & \\
        O(T(n,p)) & = O\left( \frac{n}{p} \cdot \log_2(n) + n \right)                                                    &  & \\
        e_{\max}  & = \log_2(n)                                                                                          &  & \\
        p_{\max}  & = n
    \end{flalign*}
\end{frame}

\begin{frame}{Implementierungsvarianten: Formeln: parallel Quicksort}
    Der \textbf{Worst-Case} von Quicksort (Worker-Thread-Variante) bei $p > 1$ ist:
    \begin{flalign*}
        T(n)    & = q_2 + n,                       & \\
        T(n)    & = T(n-1) + n,                    & \\
        T(n)    & = \frac{1}{2} \cdot ( n^2 + n ), & \\
        O(T(n)) & = O(n^2).                        &
    \end{flalign*}
\end{frame}

\Baumfolien

\begin{frame}[fragile, shrink=10]{Implementierungsvarianten Code}
    \begin{lstlisting}[language=C++, caption={Tiefenbasierte Thread-Erzeugung Mergesort}, label={lst:mergesortP}]
void Mergesort::mergesortP(int *liste, const int links, const int rechts, const int aktuelleEbene, const int neueThreadsBisEbene) {
    if (aktuelleEbene < neueThreadsBisEbene) {
        int lange = rechts - links + 1;
        if (lange > 1) {
            int mitte = links + ((rechts - links) / 2);
            // mergesort(liste, links, mitte);
            std::thread thread(
                static_cast<void (*)(int *, const int, const int, const int, const int)>(&Mergesort::mergesortP),
                liste, links, mitte, aktuelleEbene + 1, neueThreadsBisEbene);
            // mergesort(liste, mitte + 1, rechts);
            mergesortP(liste, mitte + 1, rechts, aktuelleEbene + 1, neueThreadsBisEbene);
            thread.join();
            mischen(liste, links, mitte, rechts, lange);
        }
    } else {
        mergesort(liste, links, rechts);
    }
};
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile, shrink=10]{Implementierungsvarianten Code}
    \begin{lstlisting}[language=C++, caption={Tiefenbasierte Thread-Erzeugung Quicksort}, label={lst:quicksortP}]
void Quicksort::quicksortP(int *liste, const int links, const int rechts, const int aktuelleEbene, const int neueThreadsBisEbene) {
    if (aktuelleEbene < neueThreadsBisEbene) {
        if (links < rechts) {
            int ml, mr;
            partitioniere(liste, links, rechts, ml, mr);
            // quicksort(liste, links, ml);
            std::thread thread(static_cast<void (*)(int *, const int, const int, const int, const int)>(&Quicksort::quicksortP), liste, links, ml, aktuelleEbene + 1, neueThreadsBisEbene);
            // quicksort(liste, mr, rechts);
            quicksortP(liste, mr, rechts, aktuelleEbene + 1, neueThreadsBisEbene);
            thread.join();
        }
    } else {
        quicksort(liste, links, rechts);
    }
};
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile, shrink=10]{Implementierungsvarianten Code}
    \begin{lstlisting}[language=C++, caption={Worker-Thread-Variante Mergesort}, label={lst:mergesortW}]
void Mergesort::mergesortW(int *liste, int links, int rechts, int workerThreads) {
    MergeWorkerPool pool(workerThreads - 1);
    pool.taskHandler = [&](int *liste, int links, int rechts, MergeWorkerPool &pool) {
        if (links < rechts) {
            int lange = rechts - links + 1;
            if (lange < Sortierverfaren::mindestLange) {
                mergesort(liste, links, rechts);
            } else {
                int mitte = links + ((rechts - links) / 2);
                auto leftHandle = pool.addTaskSmart({liste, links, mitte});
                pool.taskHandler(liste, mitte + 1, rechts, pool);
                leftHandle.wait();
                mischen(liste, links, mitte, rechts, lange);
            }
        }
    };
    // Starttask
    pool.taskHandler(liste, links, rechts, pool);
}
    \end{lstlisting}
\end{frame}

\begin{frame}[fragile, shrink=10]{Implementierungsvarianten Code}
    \begin{lstlisting}[language=C++, caption={Worker-Thread-Variante Quicksort}, label={lst:quicksortW}]
void Quicksort::quicksortW(int *liste, int links, int rechts, int workerThreads) {
    WorkerPool pool(workerThreads);
    pool.taskHandler = [](int *liste, int links, int rechts, WorkerPool &pool) {
        if (links < rechts) {
            if (rechts - links < Sortierverfaren::mindestLange) {
                quicksort(liste, links, rechts);
            } else {
                int ml, mr;
                Quicksort::partitioniere(liste, links, rechts, ml, mr);
                pool.addTask({liste, links, ml});
                pool.taskHandler(liste, mr, rechts, pool);
            }
        }
    };
    pool.addTaskWaitUntilDone({liste, links, rechts});
}
    \end{lstlisting}
\end{frame}

\begin{frame}{Optimierung}
    \Optimierung
\end{frame}

\begin{frame}{Messmethodik}
    \begin{itemize}
        \item Zufällige Listen (Arrays), gleicher Seed → reproduzierbar, vergleichbar
        \item Zeitmessung mit \texttt{chrono}, Auflösung von 100\,ns
        \item Zur Einordnung gilt: \(1\,\text{s} = 10^3\,\text{ms} = 10^9\,\text{ns}\).
        \item Zeitpunkte der Messung: unmittelbar vor und nach dem Aufruf zum Sortieren.
        \item Fast immer überprüft, ob das Ergebnis sortiert ist, um Korrektheit sicherzustellen.
        \item Einzelergebnis (Stichprobenmessung), da praxisnäher und realitätssicher.
        \item Insgesamt rund 20\,000 Einzelmessungen (Messdateien).
        \item Es wird nur auf die wichtigsten Messungen eingegangen (rund 300 Einzelmessungen).
    \end{itemize}
\end{frame}

\begin{frame}{Messmethodik (Text)}
    Zur Laufzeitmessung wurden zufällig erzeugte Listen verwendet, die stets mit demselben Seed initialisiert wurden. Dadurch sind alle Messungen reproduzierbar und miteinander vergleichbar.
    \newline
    Die Zeitmessung erfolgte mithilfe der Bibliothek \texttt{chrono}. Die gemessenen Zeiten besitzen eine Auflösung von 100\,ns und wurden entsprechend in Nanosekunden gespeichert sowie in den Diagrammen dargestellt. Zur Einordnung gilt:
    \(1\,\text{s} = 10^3\,\text{ms} = 10^9\,\text{ns}\).
    \newline
    Die Messung begann unmittelbar vor dem Aufruf des zu untersuchenden Sortieralgorithmus und endete direkt nach dessen Abschluss. Die Zeit für die Initialisierung der Testlisten wurde dabei nicht mitgemessen.
    \newline
    Nach den meisten Messungen wurde überprüft, ob die resultierende Liste korrekt sortiert ist, um die funktionale Korrektheit der Implementierung sicherzustellen.
    \newline
    In der vorliegenden Untersuchung wird jeder Datenpunkt als Einzelergebnis (Stichprobenmessung) aufgeführt. Dieser Ansatz wurde gewählt, um die reale Systemperformance unter wechselnden Lastbedingungen unverfälscht darzustellen. Da jede Messung ein in der Praxis aufgetretenes Laufzeitverhalten repräsentiert, wird auf eine Mittelwertbildung verzichtet, um auch punktuelle Latenzen oder Ausreißer, die für die Stabilität des Algorithmus relevant sind, sichtbar zu machen.
\end{frame}

\begin{frame}{Formeln: Einheiten und Skalierung}
    \begingroup
    \setlength{\belowdisplayskip}{-5pt}
    \begin{flalign*}
        x \cdot T(n) & = 2 \cdot T \left( \frac{n}{2} \right) + x \cdot n & \\
        x \cdot T(n) & =  x \cdot n \cdot \log_2(n) + x \cdot n           & \\
        x \cdot T(n) & = x \cdot \left( n \cdot \log_2(n) + n \right)     & \\
    \end{flalign*}
    \endgroup
    Aufgrund von Overheads wie z.\,B. erhöhte Speicherlatenzen durch Cache-Misses:
    \begingroup
    \setlength{\belowdisplayskip}{-10pt}
    \begin{flalign*}
        x      & = f(n,p)     & \\
        f(n,p) & \le f(n+1,p) & \\
        f(n,p) & \le f(n,p+1) & \\
    \end{flalign*}
    \endgroup
    \includegraphics[width=1\textwidth]{Abbildungen/SpeicherlatenzenDiagramm.jpg}
\end{frame}

\begin{frame}{Nebeneffekt des Skalierens mit dem Faktor $x$}

    Sollte die Standard-Formel

    \[
        T(n) = 2T\!\left(\frac{n}{2}\right) + n
    \]

    falsch sein und stattdessen diese Formel gelten

    \[
        T(n) = 2T\!\left(\frac{n}{2}\right) + (n-1)
    \]

    kann man diese auch schreiben als

    \[
        T(n) =
        2T\!\left(\frac{n}{2}\right) + \underbrace{\left(1-\frac{1}{n}\right)}_{x} \cdot n
    \]

    Dabei ist $\left(1-\frac{1}{n}\right)$ implizit auch durch $x$ repräsentiert.
    Durch diesen Nebeneffekt korrigiert der Faktor x auch gleich implizit die Formel.
    Dies macht die Formel nach dem Hochskalieren auf die sequentielle Laufzeit so präzise
    und sorgt damit dafür,
    dass die T(n,p)-Formel so exakt die untere Grenze der Laufzeitverbesserung vorhersagen kann.

\end{frame}

\section{Ergebnisse und Analyse}
\begin{frame}{Laufzeitmessungen (sequenziell)}
    % Platz für Diagramme aus \GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagramm
\end{frame}

\begin{frame}{Analyse der Threading-Methoden}
    % Vergleich Workerthreads vs. Tiefenbasierte Erzeugung
\end{frame}

\section{Diskussion und Fazit}
\begin{frame}{Beantwortung der Forschungsfrage}
    % Kernpunkte aus \BeantwortungDerForschungsfrage
\end{frame}

\begin{frame}{Zusammenfassung und Ausblick}
    % Kernpunkte aus \Zusammenfassung und \Ausblick
\end{frame}

\begin{frame}
    \centering
    \Huge Vielen Dank für Ihre Aufmerksamkeit!\\
    \vspace{1cm}
    \large Fragen und Diskussion
\end{frame}

\alleFolien

\begin{frame}[allowframebreaks]{Literatur}
    \bibliographystyle{plain}
    \bibliography{literatur}
\end{frame}

\end{document}
