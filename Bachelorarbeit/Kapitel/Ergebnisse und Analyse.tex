% Ergebnisse und Analyse.tex

\input{Kapitel/Ergebnisse und Analyse Diagramme.tex}

% Definiere Variablen
% \newcommand{\Messziel}{Messziel}

% % ----------------------
% % 4. Ergebnisse und Analyse
% % ----------------------
% \newpage
% \chapter{Ergebnisse und Analyse}
% \paragraph{Hinweis zum Umfang der Darstellung}
% \section{Grundlegende Laufzeiten abhängig von der Arraygröße}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Einfluss des Listentyps} % Listentyps: Zufall, Sortiert, InvertiertSortiert, FastSortiert, Dupliziert
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Einfluss der Arraygröße im Detail}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Tiefenbasierte Thread-Erzeugung}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Workerthreads}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Vergleich der Threading-Methoden}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% \newpage
% \section{Einfluss des Datentyps der Liste} % Listenart: int, string
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}
% % \section{Debug Vs Release}

% % ----------------------
% % 4. Ergebnisse und Analyse
% % ----------------------
% \chapter{Ergebnisse und Analyse}
% \paragraph{Hinweis zum Umfang der Darstellung}
\newcommand{\HinweisZumUmfangDerDarstellung}{
    Alle beschriebenen Messungen wurden vollständig durchgeführt und die
    entsprechenden Rohdaten liegen vor. Aufgrund des begrenzten zeitlichen
    Rahmens dieser Bachelorarbeit wird jedoch auf eine vollständige grafische
    Darstellung sowie eine detaillierte Analyse aller Messreihen verzichtet.
    Stattdessen werden im Folgenden ausgewählte, repräsentative Messungen
    dargestellt und analysiert, da diese ausreichend sind, um die theoretisch
    erwarteten Laufzeiteigenschaften der untersuchten Algorithmen zu bestätigen.
    Weitere Messdaten würden keine zusätzlichen inhaltlichen Erkenntnisse liefern,
    sondern lediglich bereits beobachtete Effekte wiederholen.
}

% \section{Grundlegende Laufzeiten abhängig von der Arraygröße}
% \subsection{Messziel} % Einleitung
\newcommand{\GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseMessziel}{
    Das Messziel besteht darin, die Abhängigkeit der sequenziellen Implementierungen von der Arraygröße grafisch darzustellen.
    Dadurch können diese Ergebnisse später mit den parallelen Varianten verglichen werden.
    Gleichzeitig dient dies als einfacher Einstieg in das Thema.
}

% \subsection{Erwartung}
\newcommand{\GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseErwartung}{
    Da die durchschnittliche Laufzeit \(O(n \log n)\) beträgt, wird auch diese bei wachsender Arraygröße erwartet.
}

% \subsection{Diagramm}
\newcommand{\GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagramm}{
    \begin{minipage}{0.5\linewidth}
        \centering
        \GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammA
        \captionof{figure}[Grundlegende Laufzeit der Sortierverfahren (Arraygröße 1 - 400M)]{}
        \label{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammA}
    \end{minipage}
    \begin{minipage}{0.5\linewidth}
        \centering
        \GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB
        \captionof{figure}[Grundlegende Laufzeit der Sortierverfahren (Arraygröße 25M - 400M, logarithmische Achsen)]{}
        \label{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammC
        \captionof{figure}[Grundlegende Laufzeit der Sortierverfahren (Arraygröße 1 - 800k, logarithmische Achsen)]{}
        \label{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammC}
    \end{minipage}
}

% \subsection{Analyse und Interpretation}
\newcommand{\GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseAnalyse}{
    In den ersten zwei Diagrammen
    (Abbildung~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammA}
    ~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB})
    ist die Veränderung der Laufzeit zu sehen, wenn die Listengröße fünfmal verdoppelt wird und bei \(2.5 \cdot 10^7\) startet.
    Beim zweiten Diagramm (Abbildung~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB}) sind die Achsen logarithmisch dargestellt, da dies die Darstellung und den Vergleich der Laufzeiten erleichtert.
    \newline
    Unter diesen beiden Diagrammen befindet sich ein drittes Diagramm (Abbildung~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammC}), in dem die gemessenen Laufzeiten ebenfalls logarithmisch dargestellt sind und der Größenbereich von \(1\) bis \(800\,000\) betrachtet wird.
    \newline
    Anhand dieser Diagramme
    (Abbildung~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB}
    ~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammC})
    ist deutlich erkennbar, dass sowohl Mergesort als auch Quicksort tatsächlich eine Laufzeit von
    \(O(n \log n)\) besitzen.
    Da die Graphen in dem logarithmischen Diagrammen
    (Abbildung~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammB} ~\ref{fig:GrundlegendeLaufzeitenAbhaengigVonDerArraygroesseDiagrammC})
    parallel zum eingezeichneten \(n \cdot \log_2(n)\)-Graphen verlaufen.
    \newline
    Zudem ist erkennbar, dass Mergesort etwa die doppelte Laufzeit von Quicksort benötigt und dass Quicksort näherungsweise ein Zeitverhalten von
    \(2 \cdot n \log_2(n)\) aufweist.
    \newline
    Da eine lineare Laufzeit auf einen Blick leichter zu interpretieren ist, wurde zusätzlich die Funktion \(32n\) eingezeichnet.
    Anhand dieser Funktion ist erkennbar, dass sie im untersuchten Zahlenbereich von \(1\) bis \(4 \cdot 10^8\) teilweise sogar eine genauere Abschätzung liefert als \(1 \cdot n \log_2(n)\).
    Daraus folgt, dass von einer gerundeten durchschnittlichen Mindestlaufzeit von \(32n\) ausgegangen werden kann.
    \newline
    Abschließend ist anzumerken, dass alle Messungen mit einer Laufzeit von kleiner oder gleich \(10^4\,\text{ns}\) aufgrund der Messtoleranz nur eine eingeschränkte Aussagekraft besitzen.
    Zwar kann mit \texttt{chrono} auf eine Auflösung von \(100\,\text{ns}\) genau gemessen werden, dennoch verbleiben natürliche Schwankungen, die insbesondere im Bereich von \(10^4\,\text{ns}\) einen erheblichen Einfluss auf die Messergebnisse haben.
}

% \section{Einfluss des Listentyps} % Listentyps: Zufall, Sortiert, InvertiertSortiert, FastSortiert, Dupliziert
% \subsection{Messziel} % Einleitung
\newcommand{\EinflussDesListentypsMessziel}{
    Der Begriff \emph{Listentyp} beschreibt in dieser Arbeit die Anfangsanordnung der Elemente in der zu sortierenden Liste.
    Untersucht werden konkret die Listentypen \emph{zufällig}, \emph{sortiert}, \emph{invertiert sortiert}, \emph{fast sortiert} sowie \emph{dupliziert}.
    Ein Beispiel für eine duplizierte Liste ist eine Liste der Größe 100, die aus 50 Einsen und 50 Zweien besteht.
    \newline
    Der Listentyp ist relevant, da Quicksort sowohl einen Best-Case als auch einen Worst-Case aufweist.
    Diese hängen vom Inhalt der zu sortierenden Liste und somit vom jeweiligen Listentyp ab.
    Gleichzeitig dient diese Messung der Vollständigkeit, sodass die Laufzeiten auch mit anderen,
    nicht in dieser Arbeit implementierten Sortieralgorithmen gut vergleichbar sind.
    Auch hierbei werden zunächst ausschließlich die sequenziellen Laufzeiten der Algorithmen gemessen.
    Zur Vollständigkeit werden zusätzlich weitere Listentypen außer zufällig und sortiert betrachtet.
}

% \subsection{Erwartung}
\newcommand{\EinflussDesListentypsErwartung}{
    Es wird erwartet, dass der Listentyp bei Mergesort nahezu keinen Einfluss auf die Laufzeit hat,
    sodass lediglich sehr geringe Laufzeitänderungen zu beobachten sind.
    Für Quicksort wird bei einer sortierten Liste der Best-Case erwartet,
    da als Pivotelement jeweils das mittlere Element gewählt wird.
    Ebenso wird erwartet, dass bei Quicksort bei Wahl des jeweils rechten Elements als Pivotelement
    bei einer sortierten Liste der Worst-Case eintritt, daher wird der Graph direkt als Worst-Case beschriftet.
}

% \subsection{Diagramm}
\newcommand{\EinflussDesListentypsDiagramm}{
    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesListentypsDiagrammA
        \captionof{figure}[Laufzeit der Sortierverfahren (Arraygröße 1 - 400M)]{}
        \label{fig:EinflussDesListentypsDiagrammA}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesListentypsDiagrammB
        \captionof{figure}[Laufzeit der Sortierverfahren (Arraygröße 25M - 400M, logarithmische Achsen)]{}
        \label{fig:EinflussDesListentypsDiagrammB}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesListentypsDiagrammC
        \captionof{figure}[Laufzeit der Sortierverfahren (Arraygröße 1 - 400M, logarithmische Achsen)]{}
        \label{fig:EinflussDesListentypsDiagrammC}
    \end{minipage}
}

% \subsection{Analyse und Interpretation}
\newcommand{\EinflussDesListentypsAnalyse}{
    Die gemessenen Daten (Abbildung~\ref{fig:EinflussDesListentypsDiagrammC}) zeigen deutlich, dass die reale Laufzeit im Best-Case unterhalb der Referenzfunktion \(n \log_2(n)\) liegt, was auf einen vorteilhaften konstanten Faktor von ca. 0,25 zurückzuführen ist.
    Dies ist darauf zurückzuführen, dass die Messungen in der Release-Version mit aktivierten Compiler-Optimierungen durchgeführt wurden.
    In der Debug-Version (ohne Compiler-Optimierungen) wurde bei einem sortierten Array der Größe von 400~Millionen Elementen hingegen eine Laufzeit von 14~s für Quicksort gemessen, welche oberhalb der berechneten Werte von \(1 \cdot n \log_2(n)\) liegt.
    Die Messungen zeigen außerdem, dass sortierte, invertiert sortierte sowie fast sortierte Arrays nahezu identische Laufzeiten aufweisen.
    Die entsprechenden Kurven würden nahezu übereinanderliegen, weshalb zugunsten der Übersichtlichkeit auf eine separate grafische Darstellung
    dieser Listentypen verzichtet wurde.
    Im Diagramm (Abbildung~\ref{fig:EinflussDesListentypsDiagrammC}) ist ebenfalls zu erkennen, dass der Worst-Case von Quicksort eine Laufzeit von \(O(n^2)\) besitzt, da dieser Graph parallel verläuft.
    Allerdings endet der Graph ab 20k, da bereits bei 40k ein Stackoverflow durch die Rekursionstiefe ausgelöst wird. Dies ließe sich durch eine iterative Version von Quicksort vermeiden.
}

% \section{Tiefenbasierte Thread-Erzeugung}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}

% \section{Tiefenbasierte Thread-Erzeugung}
% \subsection{Messziel} % Einleitung
\newcommand{\TiefenbasierteThreadErzeugungMessziel}{
    Hier wird die rekursive Variante gemessen, die einen der beiden rekursiven Selbstaufrufe in einem neuen Thread ausführt.
    Dabei gibt es jedoch ein Limit, da jeder Thread selbst Speicher benötigt und der RAM nicht unendlich groß ist.
    Hierbei soll gemessen werden, welchen Performance-Unterschied eine höhere Anzahl an Threads bewirkt.
}

% \subsection{Erwartung}
\newcommand{\TiefenbasierteThreadErzeugungErwartung}{
    Es wird der theoretisch Performance-Zuwachs \(T(n,p)\) erwartet, solange kein Hardware-Limit erreicht wird.
    Dafür skalieren wir die \(T(n,p)\)-Formel um einen Faktor, sodass sie mit der gemessenen Grundlaufzeit übereinstimmt (\(x \cdot T(n,1)\)).
    Der Faktor wird auf eine Stelle nach dem Komma gerundet und ergibt für Quicksort \(x = 2,5\) sowie für Mergesort \(x = 5\).
    Zudem wird in dieser Variante erwartet, dass Mergesort besser skaliert als Quicksort,
    da Quicksort die Liste nicht exakt in der Mitte teilt, sondern dies nur theoretisch im heuristischen Durchschnitt tut.
    Der Best Case von Quicksort sollte jedoch weiterhin wesentlich besser sein als der von Mergesort,
    da Quicksort in diesem Fall die Liste immer perfekt in der Mitte teilt.
    Außerdem wird erwartet, dass sich die Laufzeit deutlich verschlechtert, wenn mehr Threads genutzt werden als logische Prozessoren vorhanden sind,
    da der Overhead durch Thread-Initialisierung und Context-Switching zunimmt.
}

% \subsection{Diagramm}
\newcommand{\TiefenbasierteThreadErzeugungDiagramm}{
    \begin{minipage}{\linewidth}
        \centering
        \TiefenbasierteThreadErzeugungDiagrammB
        \captionof{figure}[Strong Scaling (Tiefenbasierte Thread-Erzeugung)]{Strong Scaling (Tiefenbasierte Thread-Erzeugung): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen. Quicksort kann diese Verbesserung nur im Best-Case erreichen.
            T = Tiefenbasierte Thread-Erzeugung
        }
        \label{fig:TiefenbasierteThreadErzeugungDiagrammB}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \TiefenbasierteThreadErzeugungDiagrammC
        \captionof{figure}[Weak Scaling (Tiefenbasierte Thread-Erzeugung)]{Weak Scaling (Tiefenbasierte Thread-Erzeugung): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen. Quicksort kann diese Verbesserung nur im Best-Case erreichen.
            T = Tiefenbasierte Thread-Erzeugung
        }
        \label{fig:TiefenbasierteThreadErzeugungDiagrammC}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \TiefenbasierteThreadErzeugungDiagrammA
        \captionof{figure}[Laufzeit der Sortierverfahren (Tiefenbasierte Thread-Erzeugung, Arraygröße 1 - 400M)]{
            T16 = Tiefenbasierte Thread-Erzeugung mit 16 Threads
        }
        \label{fig:TiefenbasierteThreadErzeugungDiagrammA}
    \end{minipage}
}
% \subsection{Analyse und Interpretation}
\newcommand{\TiefenbasierteThreadErzeugungAnalyse}{
    Entgegen der ursprünglichen Erwartung konnte kein signifikanter Performance Unterschied zwischen einer vollständig sortierten und einer nahezu sortierten Liste bei Quicksort festgestellt werden.
    Dieses Verhalten ist vermutlich auf Compiler-Optimierungen zurückzuführen und darauf, dass in der Implementierung nicht systematisch ein besonders ungünstiges Pivot-Element gewählt wurde.
    \newline
    Deutliche Performance-Verbesserungen sind jedoch in allen Bereichen messbar, wie theoretisch zu erwarten war.
    Für ein unsortiertes Array der Größe \(400 \, \text{Mio.}\) zeigt sich, dass Mergesort mit 16 Threads lediglich etwa 16~\% der Laufzeit der sequenziellen Variante benötigt, während Quicksort 26~\% erreicht.
    Die Laufzeit von Mergesort wächst dabei sehr regelmäßig, während Quicksort im Durchschnitt ebenfalls eine regelmäßige Steigerung der Laufzeit zeigt, jedoch sehr stark schwankt.
    \newline
    Bemerkenswert ist, dass die 16-Thread-Variante von Quicksort nur rund 85~\% der Laufzeit von Mergesort erreicht, wodurch Mergesort insgesamt überlegen ist.
    Außerdem wird deutlich, dass Performance-Vorteile erst ab einer Array-Größe von etwa 20.000 Elementen auftreten, was auf den Overhead der Thread-Erzeugung zurückzuführen ist.
    \newline
    Die starken Laufzeitschwankungen von Quicksort bei verschiedenen Listen sind auf die ungleiche Lastverteilung auf die Threads zurückzuführen
    , die eine direkte Konsequenz der tiefenbasierten Parallelisierungs-Strategie bei unbalancierten Bäumen ist.
    Bei dieser Quicksort-Variante wird die Thread-Last meist ungleich verteilt, was dazu führt, dass die genutzten Threads über die Laufzeit hinweg immer weniger werden und somit die gesamte Hardware nicht mehr vollständig ausgenutzt wird.
    Dies ist auch deutlich im Strong Scaling zu erkennen. Dort zeigt sich, dass Quicksort bei dieser Liste weiterhin an Performance gewinnt, obwohl die Threadanzahl die Anzahl der logischen Prozessoren übersteigt. Während bei Mergesort zu beobachten ist, dass die gemessene Laufzeitverbesserung nur geringfügig schlechter ausfällt als die theoretisch zu erwartende.
    \newline
    Beim Weak Scaling ist zu erkennen, dass Quicksort dort sehr schlecht abschneidet. Dies liegt ebenfalls an der unausgeglichenen Thread-Auslastung sowie daran, dass nur eine zufällige Liste gemessen wurde und kein Median über mehrere Listen verwendet wird.
    \newline
    Interessant ist auch, dass man nahezu keine Performanceverschlechterung feststellt, wenn man deutlich mehr Threads verwendet, als effektiv genutzt werden können. Erst wenn so viele Threads erstellt werden, dass dafür mehr RAM benötigt wird, als vorhanden ist, lässt sich eine erhebliche Performanceverschlechterung beobachten.
}

% \section{Workerthreads}
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}

% \section{Workerthreads}
% \subsection{Messziel} % Einleitung
\newcommand{\WorkerthreadsMessziel}{
    Hier wird die Worker-Thread-Variante nach einem Work-Stealing-Ansatz mit einer unterstützten
    Thread-Anzahl von \(N\) gemessen.
    Zusätzlich erfolgt eine Messung, welche die Grund-Overheads der Threads näherungsweise repräsentieren soll (Abbildung~\ref{fig:initZeitenDiagrammA}).
    Da in unserem Fall die Worker-Threads nach dem Sortieren nicht wiederverwendet werden,
    ist diese Messung nicht vollständig fair.
    In der Praxis würde man die Threads weiterverwenden, wodurch dieser Overhead geringer ausfallen würde,
    da Worker-Threads nur einmalig am Anfang erstellt werden würden
    und somit die Thread-Initialisierungs-Overheads bei jedem Aufruf des Sortierverfahrens wegfallen würden,
    aber ein gemeinsamer Thread-Pool für verschiedene Algorithmen würde den Rahmen dieser Arbeit sprengen.
    \newline
    Bei der Worker-Thread-Variante wurde außerdem eine Mindestgröße von 4.000 Elementen für neue Threads eingeführt.
    Dies geschieht aus dem schlichten Grund, dass sich andernfalls kein Performance-Vorteil durch zusätzliche Threads ergibt,
    da der entstehende Overhead sonst zu groß ist.
    \newline
    Grundlage der Messungen ist die in Abschnitt~\ref{sec:implementierung} erläuterte Implementierung der Worker-Thread-Variante.
}

% \subsection{Erwartung}
\newcommand{\WorkerthreadsErwartung}{
    Auch hier wird die \(T(n,p)\)-Formel zum Vorhersagen der Performanceverbesserung genutz, genau wie bei der tiefenbasierten Thread-Erzeugung.
    \newline
    Es wird erwartet, dass Mergesort in der Worker-Thread-Variante schlechtere Ergebnisse erzielt als bei der tiefenbasierten Thread-Erzeugung.
    Dies ist darauf zurückzuführen, dass sich die Arbeit bei Mergesort in dieser Variante nicht mehr perfekt auf alle Threads verteilt und das Wait nicht wegoptimiert wurde.
    \newline
    Ebenso wird erwartet, dass der Best-Case von Quicksort im Vergleich zur tiefenbasierten Variante schlechter ausfällt, da auch hier keine optimale Arbeitsaufteilung erreicht wird.
    Für den Average-Case von Quicksort wird hingegen eine bessere Performance erwartet, da der Work-Stealing-Ansatz eine gleichmäßigere Lastverteilung über mehrere Threads ermöglicht.
}

% \subsection{Diagramm}
\newcommand{\WorkerthreadsDiagramm}{
    \begin{minipage}{\linewidth}
        \centering
        \initZeitenDiagrammA
        \captionof{figure}[Laufzeit der Sortierverfahren bei einer Arraygröße von 16 Elementen]{Dieses Diagramm dient der Abschätzung der durch Threads entstehenden Overheads.
            T = Tiefenbasierte Thread-Erzeugung,
            WT = Worker-Thread-Variante
        }
        \label{fig:initZeitenDiagrammA}
    \end{minipage}
    \newline
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \WorkerthreadsDiagrammB
        \captionof{figure}[Strong Scaling (Worker-Thread)]{Strong Scaling (Worker-Thread): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen.
            WT = Worker-Thread-Variante
        }
        \label{fig:WorkerthreadsDiagrammB}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \WorkerthreadsDiagrammC
        \captionof{figure}[Weak Scaling (Worker-Thread)]{Weak Scaling (Worker-Thread): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen.
            WT = Worker-Thread-Variante
        }
        \label{fig:WorkerthreadsDiagrammC}
    \end{minipage}
    \newline
    \begin{minipage}{\linewidth}
        \centering
        \WorkerthreadsDiagrammA
        \captionof{figure}[Laufzeit der Sortierverfahren (Worker-Thread, Arraygröße 1 - 400M)]{
            WT16 = Worker-Thread-Variante mit 16 Worker-Threads
        }
        \label{fig:WorkerthreadsDiagrammA}
    \end{minipage}
}
% \subsection{Analyse und Interpretation}
\newcommand{\WorkerthreadsAnalyse}{
    Die Messergebnisse bestätigen die zuvor formulierten Erwartungen.
    Zu beachten ist, dass die Mergesort-Worker-Thread-Variante erst ab einer Array-Größe von 64.000 Elementen alle 16 Threads nutzt.
    Dies liegt am Mindestlimit von 4.000 Elementen für die Erzeugung neuer Threads.
    Man muss beachten, dass Mergesort hier langsamer ist als bei der tiefenbasierten Thread-Erzeugung, da die Last nicht mehr optimal auf alle Threads verteilt ist. Bei Quicksort hingegen zeigt sich eine deutlich bessere Leistung, da die Last hier sehr gut auf alle Threads verteilt ist.
    Dies zeigt sich auch im Strong Scaling (Abbildung~\ref{fig:WorkerthreadsDiagrammB}) und Weak Scaling (Abbildung~\ref{fig:WorkerthreadsDiagrammC}), da hier Quicksort nur minimal schlechter als die theoretisch erwartete Laufzeit ausfällt, während Mergesort im Vergleich zur anderen Variante schlechter abschneidet.
    Wenn man jetzt die Quicksort-Worker-Thread-Variante mit der Mergesort-tiefenbasierten Thread-Erzeugungsvariante vergleicht, stellt man immer noch fest, dass Quicksort im Durchschnitt doppelt so schnell ist wie Mergesort. Beim Strong Scaling ist außerdem zu beobachten, dass die Performance bei sehr vielen Threads wieder abnimmt. Ursache hierfür sind die Sperren zur Thread-Arbeitsverteilung, die in dieser Variante erforderlich für die gemeinsame Aufgaben-Queue sind. Bei sehr vielen Threads führt dies zu einem Performance-Einbruch, da jeweils nur ein Thread die Sperre belegen kann. Hinzu kommen die Kosten der reinen Initialisierungszeit, da $2^{14}$ Threads rund 1~s für ihre Erstellung benötigen.
    Im Diagramm~\ref{fig:initZeitenDiagrammA} sind die Overheads durch das Erstellen von Threads zu erkennen. Dabei fällt auf, dass sich diese Overheads nur minimal unterscheiden. Außerdem zeigt sich, dass die Quicksort-Worker-Thread-Variante die höchsten Initialisierungs-Overheads aufweist. Dies liegt daran, dass alle anderen Varianten ihren Main-Thread weiter nutzen, während die Quicksort-Worker-Thread-Variante dies nicht tut. Dadurch muss sie stets einen Thread mehr als die anderen Varianten erstellen, was zu diesem minimalen Overhead führt.
}

% \section{Einfluss des Datentyps der Liste} % Listenart: int, string
% \subsection{Messziel} % Einleitung
% \subsection{Erwartung}
% \subsection{Diagramm}
% \subsection{Analyse und Interpretation}

% \section{Einfluss des Datentyps der Liste} % Listenart: int, string
% \subsection{Messziel} % Einleitung
\newcommand{\EinflussDesDatentypsMessziel}{
    Hier wird die Zeit gemessen, die zum Sortieren von Strings benötigt wird, da dies auch ein realistischer Anwendungsfall ist.
    Dafür werden direkt die Strategien mit der besten Laufzeit miteinander verglichen.
}

% \subsection{Erwartung}
\newcommand{\EinflussDesDatentypsErwartung}{
    Auch hier wird die $T(n,p)$-Formel zur Vorhersage der Performanceverbesserung genutzt, genau wie bei den Messungen zuvor.
    Nur ist der Faktor jetzt für Quicksort $x = 13$ und für Mergesort $x = 26$.
    \newline
    Es wird erwartet, dass das Sortieren länger dauert als bei \texttt{int}, da ein String wesentlich aufwendiger zu vergleichen ist. Dies liegt daran, dass er aus mehreren Zeichen (\texttt{char}) besteht und entsprechend mehr Speicher benötigt.
    Folglich sollte der durch die Threads entstehende Overhead einen geringeren Einfluss auf die gemessene Endzeit haben.
    Dies sollte dazu führen, dass die Graphen im Strong Scaling und Weak Scaling weniger von den theoretisch erwarteten Laufzeitverbesserungen abweichen.
}

% \subsection{Diagramm}
\newcommand{\EinflussDesDatentypsDiagramm}{
    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesDatentypsDiagrammB
        \captionof{figure}[Strong Scaling (String)]{Strong Scaling (String): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen.
            T = Tiefenbasierte Thread-Erzeugung,
            WT = Worker-Thread-Variante
        }
        \label{fig:EinflussDesDatentypsDiagrammB}
    \end{minipage}

    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesDatentypsDiagrammC
        \captionof{figure}[Weak Scaling (String)]{Weak Scaling (String): Die gestrichelten Linien zeigen die theoretisch zu erwartenden Laufzeitverbesserungen.
            T = Tiefenbasierte Thread-Erzeugung,
            WT = Worker-Thread-Variante
        }
        \label{fig:EinflussDesDatentypsDiagrammC}
    \end{minipage}

    \begin{minipage}{\linewidth}
        \centering
        \EinflussDesDatentypsDiagrammA
        \captionof{figure}[Laufzeit der Sortierverfahren (String, Arraygröße 1 - 80M)]{
            T16 = Tiefenbasierte Thread-Erzeugung mit 16 Threads,
            WT16 = Worker-Thread-Variante mit 16 Worker-Threads
        }
        \label{fig:EinflussDesDatentypsDiagrammA}
    \end{minipage}
}

% \subsection{Analyse und Interpretation}
\newcommand{\EinflussDesDatentypsAnalyse}{
    Bei den Graphen zu Strong Scaling (Abbildung~\ref{fig:EinflussDesDatentypsDiagrammB}) und Weak Scaling (Abbildung~\ref{fig:EinflussDesDatentypsDiagrammC}) ist zu erkennen, dass Mergesort hier schlechter abschneidet als bei Integer-Daten, während Quicksort weiterhin nur minimal schlechter als die theoretische Laufzeit ist.
    Dass Mergesort schlechter abschneidet, liegt vermutlich daran, dass der Aufwand zum Kopieren der Teillisten bei Strings größer ist als bei Integern.
    Betrachtet man die Gesamtlaufzeit, fällt zudem auf, dass das Sortieren einer bereits sortierten Liste deutlich langsamer ist, als man erwarten würde.
    Vereinfacht ausgedrückt liegt dies am Code zur Listengenerierung, der für sortierte Listen im Durchschnitt längere Strings erzeugt als für zufällige Listen. Dies erhöht den Vergleichsaufwand und wirkt sich negativ auf die Laufzeit aus.
}