% Methodik und Versuchsaufbau.tex

% Definiere Variablen
% \newcommand{\Messziel}{Messziel}

% % ----------------------
% % 3. Methodik und Versuchsaufbau
% % ----------------------
% \newpage
% \chapter{Methodik und Versuchsaufbau}
% \section{Messumgebung und Hardware}
% % CPU, RAM, OS, Compiler
% \section{Implementierungsvarianten}
% % Sequenziell, parallel, Workerthreads, neue Threads
% \section{Messmethodik}
% % Vorgehensweise zur Laufzeitmessung, Datenerhebung

% \section{Messumgebung und Hardware}
% % CPU, RAM, OS, Compiler
\newcommand{\MessumgebungUndHardware}{
    Die relevanten Hardwarekomponenten sind im Anhang detailliert aufgeführt. Zusammenfassend wurden die Tests auf einem System mit einer 8-Kern-CPU (8 physische Kerne, 16 logische Prozessoren) und 32~GB Arbeitsspeicher durchgeführt.
    \newline
    Als Betriebssystem kam Windows~10 in der Version~22H2 zum Einsatz. Der Code wurde in \texttt{C++} implementiert und mittels CMake mit dem MSVC-Compiler kompiliert. Die Ausführung der Tests erfolgte im integrierten Terminal von Visual Studio Code in einer Release-Konfiguration. Abweichungen hiervon werden an entsprechender Stelle gesondert angegeben.
}

% \section{Implementierungsvarianten}
% % Sequenziell, parallel, Workerthreads, neue Threads
\newcommand{\Implementierungsvarianten}{
    Im Rahmen dieser Arbeit wurden folgende Implementierungsvarianten für Mergesort und Quicksort umgesetzt:
    \begin{itemize}
        \item eine rekursiv sequenzielle Variante,
        \item eine rekursive Variante mit dynamischer Thread-Erzeugung bis zu einer Tiefe $e$, welche eine Thread-Anzahl von $2^e$ unterstützt,
        \item eine Worker-Thread-Variante basierend auf einem Work-Stealing-ähnlichen Ansatz mit $N$ Threads, umgesetzt als aufgabenbasierte Rekursionsverwaltung.
    \end{itemize}
    Für die tiefenbasierte Thread-Erzeugung ändert sich in der parallelen Phase die Rekursionsgleichung von $T(n) = 2 \cdot T(n/2) + n$ zu $T(n) = 1 \cdot T(n/2) + n$. Dies liegt daran, dass die zweite Hälfte der Arbeit parallel in einem anderen Thread verarbeitet wird und somit nicht zur Laufzeit der aktuellen Ebene beiträgt.
    Durch das Auflösen dieser Rekursion über die parallelen sowie anschließend sequenziellen Ebenen hinweg lässt sich die theoretische Laufzeit in eine geschlossene Form überführen.
    Daraus ergibt sich die theoretische Laufzeit beider Sortieralgorithmen der tiefenbasierten Thread-Erzeugung, die sich durch folgende Gleichungen beschreiben lassen, ohne die durch die Threads entstehenden Overheads zu berücksichtigen:
    \begin{flalign*}
        p         & = \text{Thread-Anzahl}                                                                               &  & \\
        T(n,p)    & = 2n \left( 1 - \frac{1}{p} \right) + \frac{n}{p} \cdot \log_2\left(\frac{n}{p}\right) + \frac{n}{p} &  & \\
        O(T(n,p)) & = O\left(n + \frac{n}{p} \cdot \log_2(n)\right)                                                      &  &
    \end{flalign*}
    Hierbei ist zu beachten, dass für Quicksort im Worst-Case weiterhin eine Komplexität von $O(n^2)$ besteht. Zudem ist die Parallelisierung auf die vorhandene Rekursionstiefe begrenzt, woraus $p_{\max} = n$ folgt.
    Für die Work-Stealing-Variante ist auch keine exakte Vorhersage der Laufzeit möglich, weshalb eine approximative Abschätzung erfolgt.
    Dies liegt daran, dass sich die Threads frei die Arbeit teilen und nicht mehr fest an Ebenen gebunden sind, wodurch ein zusätzlicher Overhead entsteht.
    Unter der Annahme, dass die zusätzlichen Overheads ignoriert werden, ist die theoretische Laufzeit der Work-Stealing-Variante identisch mit der tiefenbasierten Variante.
    \newline
    Bildlich gesprochen lässt sich Mergesort als balancierter und Quicksort als unbalancierter Baum darstellen. Während die tiefenbasierte Thread-Erzeugung bis zu einer festen Ebene bei Mergesort zu einer optimalen Auslastung führt, resultiert dies bei Quicksort in einer schlechten Lastverteilung. Im Gegensatz dazu ermöglicht die Work-Stealing-Variante, dass freie Threads Aufgaben aus anderen Ästen (dem linken Teilbaum) übernehmen. Dadurch wird auch bei unbalancierten Baumstrukturen eine sehr gleichmäßige Lastverteilung erzielt, was wiederum in einer verkürzten Laufzeit resultiert.
}

% \section{Messmethodik}
% % Vorgehensweise zur Laufzeitmessung, Datenerhebung
\newcommand{\Messmethodik}{
    Zur Laufzeitmessung wurden zufällig erzeugte Listen verwendet, die stets mit demselben Seed initialisiert wurden. Dadurch sind alle Messungen reproduzierbar und miteinander vergleichbar.
    \newline
    Die Zeitmessung erfolgte mithilfe der Bibliothek \texttt{chrono}. Die gemessenen Zeiten besitzen eine Auflösung von 100\,ns und wurden entsprechend in Nanosekunden gespeichert sowie in den Diagrammen dargestellt. Zur Einordnung gilt:
    \(1\,\text{s} = 10^3\,\text{ms} = 10^9\,\text{ns}\).
    \newline
    Die Messung begann unmittelbar vor dem Aufruf des zu untersuchenden Sortieralgorithmus und endete direkt nach dessen Abschluss. Die Zeit für die Initialisierung der Testlisten wurde dabei nicht mitgemessen.
    \newline
    Nach den meisten Messungen wurde überprüft, ob die resultierende Liste korrekt sortiert ist, um die funktionale Korrektheit der Implementierung sicherzustellen.
    \newline
    Für die Darstellung in den Diagrammen wird der Übersicht halber von einer direkten 1:1-Zuordnung von theoretischer Laufzeit zu Dauer in ns ausgegangen. Diese Annahme ist jedoch stark vereinfacht, da sie nicht garantiert werden kann. Die erwarteten Werte sollten daher stets kritisch betrachtet werden.
}