% Methodik und Versuchsaufbau.tex

% Definiere Variablen
% \newcommand{\Messziel}{Messziel}

% % ----------------------
% % 3. Methodik und Versuchsaufbau
% % ----------------------
% \newpage
% \chapter{Methodik und Versuchsaufbau}
% \section{Messumgebung und Hardware}
% % CPU, RAM, OS, Compiler
% \section{Implementierungsvarianten}
% % Sequenziell, parallel, Workerthreads, neue Threads
% \section{Messmethodik}
% % Vorgehensweise zur Laufzeitmessung, Datenerhebung

% \section{Messumgebung und Hardware}
% % CPU, RAM, OS, Compiler
\newcommand{\MessumgebungUndHardware}{
    Die relevanten Hardwarekomponenten sind im Anhang detailliert aufgeführt. Zusammenfassend wurden die Tests auf einem System mit einer 8-Kern-CPU (8 physische Kerne, 16 logische Prozessoren) und 32~GB Arbeitsspeicher durchgeführt.
    \newline
    Als Betriebssystem kam Windows~10 in der Version~22H2 zum Einsatz. Der Code wurde in \texttt{C++} implementiert und mittels CMake mit dem MSVC-Compiler kompiliert. Die Ausführung der Tests erfolgte im integrierten Terminal von Visual Studio Code in einer Release-Konfiguration. Abweichungen hiervon werden an entsprechender Stelle gesondert angegeben.
}

% \section{Implementierungsvarianten}
% % Sequenziell, parallel, Workerthreads, neue Threads
\newcommand{\Implementierungsvarianten}{
    Im Rahmen dieser Arbeit wurden folgende Implementierungsvarianten für Mergesort und Quicksort umgesetzt:
    \begin{itemize}
        \item eine rekursiv sequenzielle Variante,
        \item eine rekursive Variante mit dynamischer Thread-Erzeugung bis zu einer Tiefe $e$, welche eine Thread-Anzahl von $2^e$ unterstützt (tiefenbasierte Thread-Erzeugung),
        \item eine Worker-Thread-Variante basierend auf einem Work-Stealing-ähnlichen Ansatz mit $N$ Threads, umgesetzt als aufgabenbasierte Rekursionsverwaltung.
    \end{itemize}
    Für die tiefenbasierte Thread-Erzeugung ändert sich in der parallelen Phase die Rekursionsgleichung von $T(n) = 2 \cdot T(n/2) + n$ zu $T(n) = 1 \cdot T(n/2) + n$. Dies liegt daran, dass die zweite Hälfte der Arbeit parallel in einem anderen Thread verarbeitet wird und somit nicht zur Laufzeit der aktuellen Ebene beiträgt.
    Durch das Auflösen dieser Rekursion über die parallelen sowie anschließend sequenziellen Ebenen hinweg lässt sich die theoretische Laufzeit in eine geschlossene Form überführen.
    Daraus ergibt sich die theoretische Laufzeit von Mergesort sowie die Best-Case-Laufzeit von Quicksort bei der tiefenbasierten Thread-Erzeugung,
    die sich durch folgende Gleichungen beschreiben lassen, ohne die durch die Threads entstehenden Overheads zu berücksichtigen:
    \begin{flalign*}
        p         & = \text{Thread-Anzahl}                                                                               &  & \\
        T(n,p)    & = 2n \left( 1 - \frac{1}{p} \right) + \frac{n}{p} \cdot \log_2\left(\frac{n}{p}\right) + \frac{n}{p} &  & \\
        O(T(n,p)) & = O\left( \frac{n}{p} \cdot \log_2(n) + n \right)                                                    &  &
    \end{flalign*}
    Hierbei ist zu beachten, dass die Parallelisierung auf die vorhandene Rekursionstiefe begrenzt ist, woraus $p_{\max} = n$ folgt.
    Da die Rekursionstiefe einen balacitern biänr baumes auf log2(n) ebnen begrzt ist. und dhaer ist e_max = log2(n). Da eben weise pareisrt wird ist e = log2(p) und das wird dan zu $p_{\max} = n$.
    Zudem besteht für Quicksort im Worst-Case bei $p > 1$ folgende theoretische Laufzeit:
    \begin{flalign*}
        T(n)    & = T(n-1) + n,                    & \\
        T(n)    & = \frac{1}{2} \cdot ( n^2 + n ), & \\
        O(T(n)) & = O(n^2).                        &
    \end{flalign*}
    Für die Work-Stealing-Variante ist auch keine exakte Vorhersage der Laufzeit möglich, weshalb eine approximative Abschätzung erfolgt.
    Dies liegt daran, dass sich die Threads frei die Arbeit teilen und nicht mehr fest an Ebenen gebunden sind, wodurch ein zusätzlicher Overhead entsteht.
    Unter der Annahme, dass die zusätzlichen Overheads ignoriert werden, ist die theoretische Laufzeit der Work-Stealing-Variante identisch mit der tiefenbasierten Variante.
    Natürlich unterscheiden sich die Average-Case-Laufzeiten beider Varianten in der Praxis dramatisch.
    Für diese Arbeit ist es jedoch ausreichend, nur den auch durch $T(n,p)$ beschriebenen heuristischen Average-Case zu analysieren.
    \newline
    Bildlich gesprochen lässt sich Mergesort als balancierter und Quicksort als unbalancierter Baum darstellen. Während die tiefenbasierte Thread-Erzeugung bis zu einer festen Ebene bei Mergesort zu einer optimalen Auslastung führt, resultiert dies bei Quicksort in einer schlechten Lastverteilung. Im Gegensatz dazu ermöglicht die Work-Stealing-Variante, dass freie Threads Aufgaben aus anderen Ästen (dem linken Teilbaum) übernehmen. Dadurch wird auch bei unbalancierten Baumstrukturen eine sehr gleichmäßige Lastverteilung erzielt, was wiederum in einer verkürzten Laufzeit resultiert.
}

% \section{Messmethodik}
% % Vorgehensweise zur Laufzeitmessung, Datenerhebung
\newcommand{\Messmethodik}{
    Zur Laufzeitmessung wurden zufällig erzeugte Listen verwendet, die stets mit demselben Seed initialisiert wurden. Dadurch sind alle Messungen reproduzierbar und miteinander vergleichbar.
    \newline
    Die Zeitmessung erfolgte mithilfe der Bibliothek \texttt{chrono}. Die gemessenen Zeiten besitzen eine Auflösung von 100\,ns und wurden entsprechend in Nanosekunden gespeichert sowie in den Diagrammen dargestellt. Zur Einordnung gilt:
    \(1\,\text{s} = 10^3\,\text{ms} = 10^9\,\text{ns}\).
    \newline
    Die Messung begann unmittelbar vor dem Aufruf des zu untersuchenden Sortieralgorithmus und endete direkt nach dessen Abschluss. Die Zeit für die Initialisierung der Testlisten wurde dabei nicht mitgemessen.
    \newline
    Nach den meisten Messungen wurde überprüft, ob die resultierende Liste korrekt sortiert ist, um die funktionale Korrektheit der Implementierung sicherzustellen.
    \newline
    In der vorliegenden Untersuchung wird jeder Datenpunkt als Einzelergebnis (Stichprobenmessung) aufgeführt. Dieser Ansatz wurde gewählt, um die reale Systemperformance unter wechselnden Lastbedingungen unverfälscht darzustellen. Da jede Messung ein in der Praxis aufgetretenes Laufzeitverhalten repräsentiert, wird auf eine Mittelwertbildung verzichtet, um auch punktuelle Latenzen oder Ausreißer, die für die Stabilität des Algorithmus relevant sind, sichtbar zu machen.
    \newline
    Für die Darstellung in den Diagrammen wird der Übersicht halber von einer direkten 1:1-Zuordnung von theoretischer Laufzeit zu Dauer in ns ausgegangen. Diese Annahme ist jedoch stark vereinfacht, da sie nicht garantiert werden kann. Die erwarteten Werte sollten daher stets kritisch betrachtet werden.
    \newline
    Dafür folgt hier ein praktisches Beispiel: Damit der theoretischen Laufzeit eine Zeiteinheit zugeordnet werden kann, wird eine Variable benötigt, die wir \(x\) nennen. Dieses \(x\) repräsentiert die Zeit, die ein einzelner Vergleich benötigt. Es ergeben sich folgende Gleichungen:
    \begin{flalign*}
         & T(n) = 2 \cdot T \left( \frac{n}{2} \right) + x \cdot n & \\
         & T(n) = x \cdot \left( n \cdot \log_2(n) + n \right).    &
    \end{flalign*}
    Wenn die Vergleichszeit $x = 1\,\text{ns}$ beträgt, liegt eine direkte
    1:1-Zuordnung vor. In der Praxis könnte $x$ jedoch variieren und beispielsweise
    einen Best-Case von $0,25\,\text{ns}$ sowie einen Worst-Case von $1\,\text{ms}$
    aufweisen. Durch diese Schwankungen, die unter anderem durch Speicherlatenzen entstehen,
    lässt sich die theoretische Laufzeit nie perfekt 1:1 zuordnen. Sie wird in
    der Realität immer schwanken.
}